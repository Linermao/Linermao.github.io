<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>NeRF Paper read | Linermao's kiosk</title><meta name="author" content="Linermao,86281366@qq.com"><meta name="copyright" content="Linermao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="NeRF Paper read1. PrefaceThis article will introduce NeRF and explain some interesting points from the paper: “NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis” Hereinafter refer">
<meta property="og:type" content="article">
<meta property="og:title" content="NeRF Paper read">
<meta property="og:url" content="http://example.com/2023/10/03/Advanced_Model/NeRF_PaperRead/index.html">
<meta property="og:site_name" content="Linermao&#39;s kiosk">
<meta property="og:description" content="NeRF Paper read1. PrefaceThis article will introduce NeRF and explain some interesting points from the paper: “NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis” Hereinafter refer">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/Avatar.jpg">
<meta property="article:published_time" content="2023-10-02T16:01:00.000Z">
<meta property="article:modified_time" content="2023-12-15T16:19:32.525Z">
<meta property="article:author" content="Linermao">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/Avatar.jpg"><link rel="shortcut icon" href="/images/favicon.jpg"><link rel="canonical" href="http://example.com/2023/10/03/Advanced_Model/NeRF_PaperRead/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d0547acfa82ccac854b804414ae584ec";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":100,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NeRF Paper read',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  postUpdate: '2023-12-16 00:19:32'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/Avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/index.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Linermao's kiosk"><span class="site-name">Linermao's kiosk</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">NeRF Paper read</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-02T16:01:00.000Z" title="发表于 2023-10-03 00:01:00">2023-10-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-12-15T16:19:32.525Z" title="更新于 2023-12-16 00:19:32">2023-12-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Advanced-Model/">Advanced_Model</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NeRF Paper read"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="NeRF-Paper-read"><a href="#NeRF-Paper-read" class="headerlink" title="NeRF Paper read"></a>NeRF Paper read</h1><h2 id="1-Preface"><a href="#1-Preface" class="headerlink" title="1. Preface"></a>1. Preface</h2><p>This article will introduce NeRF and explain some interesting points from the paper: <strong><em>“NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis”</em></strong> Hereinafter referred to <strong>NeRF Paper</strong>.</p>
<h2 id="2-What-is-NeRF"><a href="#2-What-is-NeRF" class="headerlink" title="2. What is NeRF"></a>2. What is NeRF</h2><p><strong>NeRF (Neural Radiance Fields)</strong> was first introduced in the best paper presented at <strong>ECCV 2020</strong>,</p>
<blockquote>
<p>We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (nonconvolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x, y, z) and viewing direction (θ, φ)) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.</p>
</blockquote>
<p>The above content comes from NeRF Paper.</p>
<p>In short, NeRF is a way to represent complex 3D scenes using only 2D posed images as supervision.</p>
<p>We can refer to the image below, where the input is a lot of 2D photos, and we get a 3D object by using NeRF.</p>
<div align="center">
<img src="/2023/10/03/Advanced_Model/NeRF_PaperRead/1.png" height="150px">
<p style="font-size:14px;">Figure 1.1</p>
<p style="font-size:14px;">(From NeRF Paper)</p>
</div>

<h2 id="3-How-it-works"><a href="#3-How-it-works" class="headerlink" title="3. How it works"></a>3. How it works</h2><p>I use four steps to interpret NeRF:</p>
<ul>
<li><strong>Radiance Fields</strong></li>
<li><strong>Neural Radiance Fields</strong></li>
<li><strong>Volume Rendering</strong></li>
<li><strong>Implementation details</strong></li>
</ul>
<p>Roughly the overall flow is shown in Figure 3.1.</p>
<div align="center">
<img src="/2023/10/03/Advanced_Model/NeRF_PaperRead/nerf_all.png" height="200px">
<p style="font-size:14px;">Figure 3.1</p>
<p style="font-size:14px;">(From NeRF Paper)</p>
</div>

<p>Let’s interpret it.</p>
<h3 id="3-1-Radiance-Fields"><a href="#3-1-Radiance-Fields" class="headerlink" title="3.1 Radiance Fields"></a>3.1 Radiance Fields</h3><p>All we need to know about Radiance Fields is that it’s a five-dimensional function:</p>
<script type="math/tex; mode=display">
\tag{3.1.1}
    L:X^3 \times W^2 \rightarrow C^3</script><script type="math/tex; mode=display">
\tag{3.1.2}
    L(x,y,z,\theta,\phi) = (r,g,b)</script><p>x,y,z represent the coordinates of a certain point in 3D space, and $\theta$, $\phi$ represent the viewing angles in spherical coordinates.</p>
<p>Simply, we can think of radiance field as describing a point in space as an RGB color point.</p>
<div align="center">
<img src="/2023/10/03/Advanced_Model/NeRF_PaperRead/2.jpg" height="150px">
<p style="font-size:14px;">Figure 3.1.1</p>
<p style="font-size:14px;">(From GRAF Paper)</p>
</div>

<h3 id="3-2-Neural-Radiance-Fields"><a href="#3-2-Neural-Radiance-Fields" class="headerlink" title="3.2 Neural Radiance Fields"></a>3.2 Neural Radiance Fields</h3><p>The difference between Neural Radiance Fields and Radiance Fields is that we use <strong>MLP</strong> to express the function implicitly, and  produces another data <strong>volume density</strong> in addition to RGB data.</p>
<script type="math/tex; mode=display">
\tag{3.2.1}
    L(x,y,z,\theta,\phi) = (r,g,b,\sigma)</script><p>This is very interesting, it’s like we assume the answer is X, and then we keep revising X to get closer to the correct answer, and obviously we don’t know how to do that, but it does, so the whole process is like a <strong>black box model</strong>.</p>
<p>In order to optimize our MLP network, we need a way to compare the output with the input, <strong>Volume rendering</strong> is a good way to do this.</p>
<h3 id="3-3-Volume-Rendering"><a href="#3-3-Volume-Rendering" class="headerlink" title="3.3 Volume Rendering"></a>3.3 Volume Rendering</h3><p>In simple terms, volume rendering is the process of <strong>rendering a generated 3D model into a 2D image</strong>. </p>
<p>Why would we do this? Because computer screens are 2D! It just looks like it’s 3D.</p>
<p>Maybe this is a little confusing, so let me explain it a little bit more.</p>
<p>When 3D games appeared on the screen, people thought it was incredible. How did this happen? We can assume that the player’s point of view is a laser emitter, we can easily calculate the distance from the laser to the object we encounter in the 2D view, the computer calculates this distance, and renders the illuminated object according to a certain proportion, thus producing a 3D visual effect.</p>
<p>(There was supposed to be a very nice picture here, but I couldn’t find it TOT)</p>
<p>So, once we compressed it back to 2D, we can see the model we generated on the screen.<br>Let’s assume that a light is emitted from a camera (In computer graphics, light is emitted from a camera). Taking into account all the points on this ray generated by the neural radiance field in the first step, we can use the magic function (3.3.1) to obtain the RGB data of the given point on this ray at this angle.</p>
<p>The magic function is below:</p>
<script type="math/tex; mode=display">
\tag{3.3.1}
    C(\mathbf{r}) = \int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t))\mathbf{c}(\mathbf{r}(t),\mathbf{d}) dt,\  where \  T(t) = exp(- \int_{t_n}^{t} \sigma (\mathbf{r}(s))ds)</script><p>For practical use, we use the discretized formulation:</p>
<script type="math/tex; mode=display">
\tag{3.3.2}
    \hat{C}(\mathbf{r}) = \sum_{i=1}^{N}T_i (1-exp(-\sigma_{i} \delta_{i}))\mathbf{c}_i,\  where \ T(t) = exp(- \sum_{j=1}^{i-1} \sigma_{j} \delta_{j})</script><p>Where <strong>$C$</strong> represents the <strong>color</strong>, <strong>$\sigma$</strong> represents the <strong>volume density</strong>, <strong>$r$</strong> and <strong>$d$</strong> represent the <strong>distance</strong> and <strong>direction</strong> on the camera ray, and <strong>$t$</strong> represents the <strong>distance</strong> of the sampling point on the camera ray from the camera optical center.</p>
<div align="center">
<img src="/2023/10/03/Advanced_Model/NeRF_PaperRead/volume_rendering.png" height="300px">
<p style="font-size:14px;">Figure 3.3.1</p>
<p style="font-size:14px;">(From Internet)</p>
</div>

<p>Of course, we don’t need to think about how the formula is derived. It takes a little bit of work to figure out this formula, so we’ll come back to it much later.</p>
<p>Since this formulation is naturally differentiable, we can use gradient descent to optimize the network .After a certain number of iterations, we can obtain a perfect network model, which can generate a 3D model from a 2D image.</p>
<h3 id="3-4-Implementation-details"><a href="#3-4-Implementation-details" class="headerlink" title="3.4 Implementation details"></a>3.4 Implementation details</h3><p>In order to improve the accuracy, the position encoding method is also used in the paper.</p>
<p>More details are discussed in the code analysis section.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Linermao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/10/03/Advanced_Model/NeRF_PaperRead/">http://example.com/2023/10/03/Advanced_Model/NeRF_PaperRead/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Linermao's kiosk</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/images/Avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/22/HexoBuilding/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/" title="云服务器配置（等待完善）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">云服务器配置（等待完善）</div></div></a></div><div class="next-post pull-right"><a href="/2023/09/07/Deep_Learning_Practice/Train_CIFAR10_by_ResNet18/" title="Train CIFAR10 by ResNet18"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Train CIFAR10 by ResNet18</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/Avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Linermao</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Linermao"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Linermao" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:862813266@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is Linermao's Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#NeRF-Paper-read"><span class="toc-text">NeRF Paper read</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Preface"><span class="toc-text">1. Preface</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-What-is-NeRF"><span class="toc-text">2. What is NeRF</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-How-it-works"><span class="toc-text">3. How it works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Radiance-Fields"><span class="toc-text">3.1 Radiance Fields</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Neural-Radiance-Fields"><span class="toc-text">3.2 Neural Radiance Fields</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Volume-Rendering"><span class="toc-text">3.3 Volume Rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Implementation-details"><span class="toc-text">3.4 Implementation details</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/12/17/Tricks/Tailscale/" title="Use Tailscale to control remote device（Somethings wrong, waiting...）"><img src="/img/top-img/Tricks/Tailscale.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Use Tailscale to control remote device（Somethings wrong, waiting...）"/></a><div class="content"><a class="title" href="/2023/12/17/Tricks/Tailscale/" title="Use Tailscale to control remote device（Somethings wrong, waiting...）">Use Tailscale to control remote device（Somethings wrong, waiting...）</a><time datetime="2023-12-17T08:23:10.000Z" title="发表于 2023-12-17 16:23:10">2023-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/11/Advanced_Model/ViT_PaperRead/" title="ViT_PaperRead"><img src="/img/top-img/Advanced_Model/ViT_PaperRead.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ViT_PaperRead"/></a><div class="content"><a class="title" href="/2023/12/11/Advanced_Model/ViT_PaperRead/" title="ViT_PaperRead">ViT_PaperRead</a><time datetime="2023-12-11T08:23:10.000Z" title="发表于 2023-12-11 16:23:10">2023-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/11/Advanced_Model/CLIP_PaperRead/" title="CLIP Paper read (Waiting for perfection)"><img src="/img/top-img/Advanced_Model/CLIP_PaperRead.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CLIP Paper read (Waiting for perfection)"/></a><div class="content"><a class="title" href="/2023/12/11/Advanced_Model/CLIP_PaperRead/" title="CLIP Paper read (Waiting for perfection)">CLIP Paper read (Waiting for perfection)</a><time datetime="2023-12-10T16:01:00.000Z" title="发表于 2023-12-11 00:01:00">2023-12-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/08/Advanced_Model/Transformer_Code/" title="Transformer_Code"><img src="/img/top-img/Advanced_Model/Transformer_Code.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer_Code"/></a><div class="content"><a class="title" href="/2023/12/08/Advanced_Model/Transformer_Code/" title="Transformer_Code">Transformer_Code</a><time datetime="2023-12-08T08:23:10.000Z" title="发表于 2023-12-08 16:23:10">2023-12-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/12/07/Advanced_Model/Transformer_PaperRead/" title="Transformer_PaperRead"><img src="/img/top-img/Advanced_Model/Transformer_PaperRead.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer_PaperRead"/></a><div class="content"><a class="title" href="/2023/12/07/Advanced_Model/Transformer_PaperRead/" title="Transformer_PaperRead">Transformer_PaperRead</a><time datetime="2023-12-07T08:23:10.000Z" title="发表于 2023-12-07 16:23:10">2023-12-07</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Linermao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><br>
<a href="https://beian.miit.gov.cn/" target="_blank">浙ICP备2023022422号-1</a>
<br>
<img src = '/img/gongan.png'>
<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33030302001279" target="_blank">浙公网安备 33030302001279号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>